{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a3c8c0b-7e5f-4285-848f-5ed4ee6e412a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm  # 导入 tqdm 库\n",
    "from abc import abstractmethod\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch_optimizer as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from ldm.modules.diffusionmodules.openaimodel import UNetModel\n",
    "from taming.modules.diffusionmodules.model import EncodertoNoise\n",
    "from mobilefacenet import MobileFacenet\n",
    "\n",
    "# 检查是否有GPU可用\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"GPU Name: {device_name}\")\n",
    "else:\n",
    "    print(\"No GPU available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f46c01-27c4-41ba-a035-c54b5657bee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VQModel(\n",
       "  (decoder): Decoder(\n",
       "    (conv_in): Conv2d(3, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (mid): Module(\n",
       "      (block_1): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (attn_1): AttnBlock(\n",
       "        (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (block_2): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (up): ModuleList(\n",
       "      (0): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "      )\n",
       "      (1): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "        (upsample): Upsample(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): Module(\n",
       "        (block): ModuleList(\n",
       "          (0-2): 3 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "        (upsample): Upsample(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (quantize): VectorQuantizer2(\n",
       "    (embedding): Embedding(8192, 3)\n",
       "  )\n",
       "  (post_quant_conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1 : 实例化vqmodel\n",
    "# 加载模型参数\n",
    "ckpt_path = 'VQf4model.ckpt'\n",
    "checkpoint = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
    "\n",
    "# 简化版VQModel的类\n",
    "class VQModel(torch.nn.Module):\n",
    "    def __init__(self, ddconfig, embed_dim=3,n_embed=8192):\n",
    "        super().__init__()\n",
    "        from taming.modules.diffusionmodules.model import Encoder, Decoder\n",
    "        from taming.modules.vqvae.quantize import VectorQuantizer2 as VectorQuantizer\n",
    "        # self.encoder = Encoder(**ddconfig)\n",
    "        self.decoder = Decoder(**ddconfig)\n",
    "        self.quantize = VectorQuantizer(n_embed, embed_dim, beta=0.25,\n",
    "                                        remap=None,\n",
    "                                        sane_index_shape=False)\n",
    "        # self.quant_conv = torch.nn.Conv2d(ddconfig[\"z_channels\"], embed_dim, 1)\n",
    "        self.post_quant_conv = torch.nn.Conv2d(embed_dim, ddconfig[\"z_channels\"], 1)\n",
    "\n",
    "    # def encode(self, x):  # 修改方法名称，避免与属性名冲突\n",
    "    #     h = self.quant_conv(self.encoder(x))\n",
    "    #     return h\n",
    "\n",
    "    def decode(self, x, force_not_quantize=False):  # 修改方法名称，避免与属性名冲突\n",
    "        if not force_not_quantize:\n",
    "            quant, emb_loss, info = self.quantize(x)\n",
    "        else:\n",
    "            quant = x\n",
    "        dec = self.decoder(self.post_quant_conv(quant))\n",
    "        return dec\n",
    "\n",
    "# 初始化简化版模型\n",
    "vq_model = VQModel(  # 实例化对象的名称改为小写以避免与类名混淆\n",
    "    ddconfig={\n",
    "        'double_z': False,\n",
    "        'z_channels': 3,\n",
    "        'resolution': 256,\n",
    "        'in_channels': 3,\n",
    "        'out_ch': 3,\n",
    "        'ch': 128,\n",
    "        'ch_mult': [1, 2, 4],\n",
    "        'num_res_blocks': 2,\n",
    "        'attn_resolutions': [],\n",
    "        'dropout': 0.0\n",
    "    },\n",
    "    embed_dim=3,\n",
    "    n_embed=8192\n",
    ")\n",
    "\n",
    "# 加载权重\n",
    "# 过滤掉与模型不相关的参数\n",
    "if 'model_state_dict' in checkpoint:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "elif 'state_dict' in checkpoint:\n",
    "    state_dict = checkpoint['state_dict']\n",
    "else:\n",
    "    state_dict = checkpoint  # 如果checkpoint文件本身就是状态字典\n",
    "\n",
    "filtered_state_dict = {k: v for k, v in state_dict.items() if k in vq_model.state_dict()}\n",
    "vq_model.load_state_dict(filtered_state_dict, strict=False)\n",
    "\n",
    "vq_model = vq_model.to(device)\n",
    "for param in vq_model.parameters():\n",
    "    param.requires_grad = False\n",
    "# 设置模型为评估模式   \n",
    "vq_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ccf385-8ab5-46dc-ba41-54b6526fba79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=224, out_features=896, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=896, out_features=896, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(3, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1-2): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 224, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 224, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(224, 224, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 224, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(224, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=448, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 448, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(224, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 448, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(448, 1344, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(448, 448, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 448, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=448, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 448, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 448, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(448, 1344, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(448, 448, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(448, 448, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 448, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(448, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=672, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 672, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(448, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 672, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(672, 2016, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(672, 672, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 672, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=672, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 672, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 672, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(672, 2016, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(672, 672, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(672, 672, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 672, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(672, 896, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=896, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(896, 896, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(672, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(896, 2688, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(896, 896, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (11): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(896, 896, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=896, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(896, 896, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(896, 2688, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(896, 896, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(896, 896, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=896, out_features=896, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(896, 896, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): AttentionBlock(\n",
       "      (norm): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "      (qkv): Conv1d(896, 2688, kernel_size=(1,), stride=(1,))\n",
       "      (attention): QKVAttentionLegacy()\n",
       "      (proj_out): Conv1d(896, 896, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(896, 896, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=896, out_features=896, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(896, 896, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0-1): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1792, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1792, 896, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=896, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(896, 896, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(896, 2688, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(896, 896, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1568, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1568, 896, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=896, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(896, 896, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1568, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(896, 2688, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(896, 896, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(896, 896, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1568, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1568, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=672, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 672, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1568, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 672, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(672, 2016, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(672, 672, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1344, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1344, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=672, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 672, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1344, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 672, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(672, 2016, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(672, 672, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1120, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1120, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=672, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 672, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1120, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 672, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(672, 2016, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(672, 672, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1120, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1120, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=448, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 448, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1120, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 448, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(448, 1344, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(448, 448, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(896, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=448, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 448, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(896, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 448, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(448, 1344, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(448, 448, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 672, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(672, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=448, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 448, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(672, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 448, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(448, 1344, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(448, 448, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 672, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(672, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 224, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(672, 224, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10-11): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 448, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(448, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=896, out_features=224, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 224, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(448, 224, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 224, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(224, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 2 : 实例化Onestep模型和多步模型\n",
    "unet_config = {\n",
    "    \"image_size\": 64,\n",
    "    \"in_channels\": 3,\n",
    "    \"out_channels\": 3,\n",
    "    \"model_channels\": 224,\n",
    "    \"attention_resolutions\": [8, 4, 2],\n",
    "    \"num_res_blocks\": 2,\n",
    "    \"channel_mult\": [1, 2, 3, 4],\n",
    "    \"num_head_channels\": 32,\n",
    "    \"use_checkpoint\": False  # 禁用checkpoint\n",
    "}\n",
    "\n",
    "onestep = UNetModel(**unet_config)\n",
    "\n",
    "ckpt_path_u = 'ddim_onestep.ckpt'\n",
    "checkpoint_u = torch.load(ckpt_path_u, map_location=device, weights_only=True)\n",
    "\n",
    "if 'model_state_dict' in checkpoint_u:\n",
    "    state_dict = checkpoint_u['model_state_dict']\n",
    "elif 'state_dict' in checkpoint_u:\n",
    "    state_dict = checkpoint_u['state_dict']\n",
    "else:\n",
    "    state_dict = checkpoint_u  # 如果checkpoint文件本身就是状态字典\n",
    "\n",
    "filtered_state_dict = {k: v for k, v in state_dict.items() if k in onestep.state_dict()}\n",
    "onestep.load_state_dict(filtered_state_dict, strict=False)\n",
    "\n",
    "onestep = onestep.to(device)\n",
    "for param in onestep.parameters():\n",
    "    param.requires_grad = False\n",
    "# # 设置模型为评估模式   \n",
    "onestep.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1795e91-4ece-4794-ba73-0a463a8714ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileFacenet(\n",
       "  (conv1): ConvBlock(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (prelu): PReLU(num_parameters=64)\n",
       "  )\n",
       "  (dw_conv1): ConvBlock(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (prelu): PReLU(num_parameters=64)\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=128)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=128)\n",
       "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=128)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=128)\n",
       "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=128)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=128)\n",
       "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=128)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=128)\n",
       "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=128)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=128)\n",
       "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=256)\n",
       "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=256)\n",
       "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=256)\n",
       "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=256)\n",
       "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=256)\n",
       "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=256)\n",
       "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=256)\n",
       "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=512)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=512)\n",
       "        (6): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=256)\n",
       "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): PReLU(num_parameters=256)\n",
       "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv2): ConvBlock(\n",
       "    (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (prelu): PReLU(num_parameters=512)\n",
       "  )\n",
       "  (linear7): ConvBlock(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(7, 6), stride=(1, 1), groups=512, bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (linear1): ConvBlock(\n",
       "    (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3:定义预训练验证模型\n",
    "verifier = MobileFacenet()\n",
    "verifier.to(device)\n",
    "# 确保文件存在且可访问\n",
    "# 加载模型参数，直接指定设备\n",
    "ckpt = torch.load('068.ckpt', map_location=device, weights_only=False)\n",
    "verifier.load_state_dict(ckpt['net_state_dict']) if ckpt else print(\"Failed to load model parameters.\")\n",
    "# 设置预训练模型的所有参数为不需要梯度\n",
    "for param in verifier.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 确保模型处于评估模式\n",
    "verifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "683adab7-e7fc-4c1d-9a2e-f77adfc061d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncodertoNoise(\n",
       "  (conv_in): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (down): ModuleList(\n",
       "    (0): Module(\n",
       "      (block): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (attn): ModuleList()\n",
       "      (downsample): Downsample(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (block): ModuleList(\n",
       "        (0): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (attn): ModuleList()\n",
       "      (downsample): Downsample(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "      )\n",
       "    )\n",
       "    (2): Module(\n",
       "      (block): ModuleList(\n",
       "        (0): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (attn): ModuleList()\n",
       "    )\n",
       "  )\n",
       "  (mid): Module(\n",
       "    (block_1): ResnetBlock(\n",
       "      (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (attn_1): AttnBlock(\n",
       "      (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "      (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (block_2): ResnetBlock(\n",
       "      (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "  (conv_out_mean): Conv2d(512, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_out_std): Conv2d(512, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 4:实例化编码模型\n",
    "ddconfig={\n",
    "        'double_z': False,\n",
    "        'z_channels': 3,\n",
    "        'resolution': 256,\n",
    "        'in_channels': 1,\n",
    "        'out_ch': 3,\n",
    "        'ch': 128,\n",
    "        'ch_mult': [1, 2, 4],\n",
    "        'num_res_blocks': 2,\n",
    "        'attn_resolutions': [],\n",
    "        'dropout': 0.0\n",
    "    }\n",
    "\n",
    "Encode2N = EncodertoNoise(**ddconfig).to(device)\n",
    "\n",
    "Encode2N.train()\n",
    "# 假设预训练的权重保存在 checkpoint_path 位置\n",
    "checkpoint_path = 'Encode2N.ckpt'\n",
    "\n",
    "# 加载预训练的参数\n",
    "pretrained_dict = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "\n",
    "# 加载权重到模型\n",
    "Encode2N.load_state_dict(pretrained_dict)\n",
    "\n",
    "# 确保模型处于训练模式\n",
    "Encode2N.train()\n",
    "# 现在 Encode2N 已经加载了预训练的参数并且可以训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c8aaac3-7729-452a-9328-d03d9d02d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5 : 定义数据加载器\n",
    "# 数据转换\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图像转换为张量\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # 将像素值限制在-1到1之间\n",
    "])\n",
    "\n",
    "# 自定义数据集\n",
    "class RealPalmDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        \n",
    "        for subfolder2 in os.listdir(root_dir):\n",
    "            subfolder2_path = os.path.join(root_dir, subfolder2)\n",
    "            if os.path.isdir(subfolder2_path):\n",
    "                for filenameB in os.listdir(subfolder2_path):\n",
    "                    image_path = os.path.join(subfolder2_path, filenameB)\n",
    "                    if os.path.isfile(image_path):\n",
    "                        self.image_paths.append(image_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('L')  # 将图像转为RGB模式\n",
    "        image = image.resize((256, 256))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# 定义real_image_folder路径\n",
    "Bezier_image_folder = '/root/onethingai-fs/Bezier'\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "B = RealPalmDataset(Bezier_image_folder, transform=transform2)\n",
    "\n",
    "train_loader = DataLoader(B, \n",
    "                          batch_size=2, \n",
    "                          shuffle=True, \n",
    "                          num_workers=16, \n",
    "                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a47cea96-2744-43c1-9cc5-83d1b713d09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   2%|▏         | 1/60 [1:25:52<84:26:19, 5152.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Loss: 0.0261, L_ID:0.0097, L_kl:0.0164\n",
      "Model parameters saved to Encode2N.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   3%|▎         | 2/60 [2:51:47<83:02:26, 5154.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/60], Loss: 0.0446, L_ID:0.0274, L_kl:0.0172\n",
      "Model parameters saved to Encode2N.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   5%|▌         | 3/60 [4:17:40<81:35:49, 5153.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/60], Loss: 0.0330, L_ID:0.0196, L_kl:0.0135\n",
      "Model parameters saved to Encode2N.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   7%|▋         | 4/60 [5:43:34<80:10:10, 5153.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/60], Loss: 0.0329, L_ID:0.0203, L_kl:0.0126\n",
      "Model parameters saved to Encode2N.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   7%|▋         | 4/60 [5:44:24<80:21:41, 5166.09s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m N1, N2, mu, std \u001b[38;5;241m=\u001b[39m Encode2N(bezier)\n\u001b[1;32m     27\u001b[0m fake1 \u001b[38;5;241m=\u001b[39m vq_model\u001b[38;5;241m.\u001b[39mdecode(onestep(N1,t))\n\u001b[0;32m---> 28\u001b[0m fake2 \u001b[38;5;241m=\u001b[39m vq_model\u001b[38;5;241m.\u001b[39mdecode(\u001b[43monestep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 计算身份一致性损失\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# 调整大小为batch_size*3*112*96,因为mobilefacenet的输入大小为112*96\u001b[39;00m\n\u001b[1;32m     33\u001b[0m fake1_resized \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(fake1, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m112\u001b[39m, \u001b[38;5;241m96\u001b[39m), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/onethingai-tmp/latent-diffusion-final/ldm/modules/diffusionmodules/openaimodel.py:723\u001b[0m, in \u001b[0;36mUNetModel.forward\u001b[0;34m(self, x, timesteps, context, y, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m (\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    721\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust specify y if and only if the model is class-conditional\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m hs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 723\u001b[0m t_emb \u001b[38;5;241m=\u001b[39m \u001b[43mtimestep_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepeat_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_embed(t_emb)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/onethingai-tmp/latent-diffusion-final/ldm/modules/diffusionmodules/util.py:162\u001b[0m, in \u001b[0;36mtimestep_embedding\u001b[0;34m(timesteps, dim, max_period, repeat_only)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m repeat_only:\n\u001b[1;32m    161\u001b[0m     half \u001b[38;5;241m=\u001b[39m dim \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 162\u001b[0m     freqs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_period\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhalf\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     args \u001b[38;5;241m=\u001b[39m timesteps[:, \u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m*\u001b[39m freqs[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    166\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([torch\u001b[38;5;241m.\u001b[39mcos(args), torch\u001b[38;5;241m.\u001b[39msin(args)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def kl_divergence_loss(mu: torch.Tensor, sigma: torch.Tensor) -> torch.Tensor:\n",
    "    # 根据给定的公式计算KL散度损失\n",
    "    loss_kl = -0.5 * torch.mean(1 + torch.log(sigma**2) - mu**2 - sigma**2)\n",
    "    return loss_kl\n",
    "\n",
    "optimizer = torch.optim.AdamW(Encode2N.parameters(), lr=4.5e-06)\n",
    "\n",
    "# 设置余弦学习率调度器，从第1个周期开始调度，T_max设为10\n",
    "cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-7)\n",
    "\n",
    "# 设置训练周期数为 60\n",
    "num_epochs = 60\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc='Epochs'):\n",
    "    \n",
    "    # 检查批次的数据\n",
    "    for bezier in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        bezier = bezier.to(device)\n",
    "       \n",
    "        t = torch.full((bezier.shape[0],), 999, device=device, dtype=torch.long)\n",
    "        \n",
    "        N1, N2, mu, std = Encode2N(bezier)\n",
    "        \n",
    "        fake1 = vq_model.decode(onestep(N1,t))\n",
    "        fake2 = vq_model.decode(onestep(N2,t))\n",
    "\n",
    "        \n",
    "        # 计算身份一致性损失\n",
    "        # 调整大小为batch_size*3*112*96,因为mobilefacenet的输入大小为112*96\n",
    "        fake1_resized = F.interpolate(fake1, size=(112, 96), mode='bilinear', align_corners=False)\n",
    "        fake2_resized = F.interpolate(fake2, size=(112, 96), mode='bilinear', align_corners=False)\n",
    "\n",
    "        o1 = verifier(fake1_resized)\n",
    "        o2 = verifier(fake2_resized)\n",
    "        # 对o1和o2进行L2范数归一化\n",
    "        o1_normalized = nn.functional.normalize(o1, p=2, dim=1)\n",
    "        o2_normalized = nn.functional.normalize(o2, p=2, dim=1)\n",
    "        # 计算o1和o2的余弦相似度\n",
    "        cosine_similarity = nn.functional.cosine_similarity(o1_normalized, o2_normalized, dim=1)\n",
    "        L_ID = (1-cosine_similarity).mean()\n",
    "\n",
    "        L_kl = kl_divergence_loss(mu, std)\n",
    "\n",
    "        loss =  L_ID + L_kl  \n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    # 每个周期都使用余弦调度\n",
    "    if epoch>=30:\n",
    "        cosine_scheduler.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, L_ID:{L_ID.item():.4f}, L_kl:{L_kl.item():.4f}')\n",
    "    \n",
    "    # 每10个周期保存一次模型参数\n",
    "\n",
    "    torch.save(Encode2N.state_dict(), 'Encode2N.ckpt')\n",
    "    print(\"Model parameters saved to Encode2N.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
